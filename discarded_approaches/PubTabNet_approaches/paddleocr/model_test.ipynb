{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to fix paddleocr installation error:\n",
    "- `brew install mupdf swig freetype`\n",
    "- `pip install https://github.com/pymupdf/PyMuPDF/archive/master.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: /Users/simon/Documents/neural_networks_ocr_project/neural_networks_seminar\n",
      "Absolute path: /Users/simon/Documents/neural_networks_ocr_project/neural_networks_seminar/data/PubTabNet\n"
     ]
    }
   ],
   "source": [
    "# Setup path in .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "# Get absolut path to proeject root\n",
    "load_dotenv()\n",
    "data_path = os.getenv(\"PUBTABNET_DATA_DIR\")\n",
    "\n",
    "project_root_dir = os.path.dirname(os.path.abspath(\"../\"))\n",
    "print(\"Project root dir:\", project_root_dir)\n",
    "\n",
    "data_dir = os.getenv(\"PUBTABNET_DATA_DIR\")\n",
    "absolute_dir = project_root_dir + data_dir\n",
    "print(\"Absolute path:\", absolute_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon/Documents/neural_networks_ocr_project/neural_networks_seminar/data/PubTabNet/test/PMC515297_004_00.png\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(img_path)\n\u001b[1;32m      6\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m----> 7\u001b[0m plt\u001b[39m.\u001b[39mimshow(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Test load the image and display it\n",
    "img_name = \"PMC515297_004_00\"\n",
    "img_path = f\"{absolute_dir}/test/{img_name}.png\"\n",
    "print(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/08/12 15:34:31] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/simon/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/simon/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/simon/opt/anaconda3/envs/s2s_learning_seminar/lib/python3.11/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/simon/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2023/08/12 15:34:34] ppocr DEBUG: dt_boxes num : 25, elapse : 0.15508103370666504\n",
      "[2023/08/12 15:34:34] ppocr DEBUG: cls num  : 25, elapse : 0.4112985134124756\n",
      "[2023/08/12 15:34:43] ppocr DEBUG: rec_res num  : 25, elapse : 9.281344175338745\n",
      "Result of PaddleOCR:\n",
      "[[[33.0, 4.0], [137.0, 4.0], [137.0, 16.0], [33.0, 16.0]], ('(a) Geographical grouping', 0.9816731810569763)]\n",
      "[[[59.0, 25.0], [112.0, 25.0], [112.0, 36.0], [59.0, 36.0]], ('Groups in set 1', 0.9839702844619751)]\n",
      "[[[218.0, 25.0], [285.0, 25.0], [285.0, 36.0], [218.0, 36.0]], ('Source of Variation', 0.984840989112854)]\n",
      "[[[381.0, 25.0], [453.0, 25.0], [453.0, 36.0], [381.0, 36.0]], ('Percentage Variation', 0.9950100779533386)]\n",
      "[[[3.0, 46.0], [166.0, 47.0], [166.0, 60.0], [3.0, 59.0]], ('Group 1  North: Bihar and Orissa populations', 0.9873514771461487)]\n",
      "[[[226.0, 49.0], [277.0, 49.0], [277.0, 59.0], [226.0, 59.0]], ('Among groups', 0.9985296130180359)]\n",
      "[[[407.0, 57.0], [429.0, 57.0], [429.0, 71.0], [407.0, 71.0]], ('0.97', 0.9219688177108765)]\n",
      "[[[408.0, 48.0], [428.0, 48.0], [428.0, 59.0], [408.0, 59.0]], ('0.29', 0.9993225336074829)]\n",
      "[[[6.0, 59.0], [164.0, 59.0], [164.0, 71.0], [6.0, 71.0]], ('Group 2  South-west: Karnataka populations', 0.9877808690071106)]\n",
      "[[[200.0, 59.0], [303.0, 59.0], [303.0, 71.0], [200.0, 71.0]], ('Among populations in groups', 0.98994380235672)]\n",
      "[[[5.0, 70.0], [164.0, 70.0], [164.0, 79.0], [5.0, 79.0]], ('Group 3  South-east: Tamil Nadu Populations', 0.9939044713973999)]\n",
      "[[[40.0, 78.0], [131.0, 78.0], [131.0, 91.0], [40.0, 91.0]], ('(b) Linguistic grouping', 0.9802011251449585)]\n",
      "[[[219.0, 69.0], [285.0, 69.0], [285.0, 79.0], [219.0, 79.0]], ('Within populations', 0.9998506903648376)]\n",
      "[[[407.0, 69.0], [429.0, 69.0], [429.0, 80.0], [407.0, 80.0]], ('98.74', 0.9998890161514282)]\n",
      "[[[57.0, 100.0], [114.0, 100.0], [114.0, 113.0], [57.0, 113.0]], ('Groups in set 2', 0.9845021367073059)]\n",
      "[[[10.0, 111.0], [160.0, 111.0], [160.0, 124.0], [10.0, 124.0]], ('Group 1  Indo-European: Orissa and Bihar', 0.9624482989311218)]\n",
      "[[[217.0, 102.0], [286.0, 102.0], [286.0, 112.0], [217.0, 112.0]], ('Source of Variation', 0.9965395927429199)]\n",
      "[[[382.0, 102.0], [454.0, 102.0], [454.0, 112.0], [382.0, 112.0]], ('Percentage Variation', 0.9978240132331848)]\n",
      "[[[225.0, 112.0], [278.0, 112.0], [278.0, 123.0], [225.0, 123.0]], ('Among groups', 0.9991996884346008)]\n",
      "[[[407.0, 110.0], [429.0, 110.0], [429.0, 125.0], [407.0, 125.0]], ('0.69', 0.9737226963043213)]\n",
      "[[[12.0, 122.0], [158.0, 122.0], [158.0, 131.0], [12.0, 131.0]], ('Group 2  Dravidian: Southern populations', 0.9986150860786438)]\n",
      "[[[200.0, 120.0], [302.0, 121.0], [302.0, 134.0], [199.0, 133.0]], ('Among populations in groups', 0.9796639680862427)]\n",
      "[[[407.0, 120.0], [429.0, 120.0], [429.0, 134.0], [407.0, 134.0]], ('0.94', 0.9129291772842407)]\n",
      "[[[218.0, 131.0], [285.0, 132.0], [285.0, 143.0], [218.0, 142.0]], ('Within populations', 0.9898102283477783)]\n",
      "[[[406.0, 130.0], [430.0, 130.0], [430.0, 144.0], [406.0, 144.0]], ('98.40', 0.9988275766372681)]\n"
     ]
    }
   ],
   "source": [
    "# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n",
    "# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n",
    "# to switch the language model in order.\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=False) # need to run only once to download and load model into memory\n",
    "result = ocr.ocr(img_path, cls=True)\n",
    "print(\"Result of PaddleOCR:\")\n",
    "for idx in range(len(result)):\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw result\n",
    "from PIL import Image\n",
    "result = result[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "boxes = [line[0] for line in result]\n",
    "txts = [line[1][0] for line in result]\n",
    "scores = [line[1][1] for line in result]\n",
    "im_show = draw_ocr(image, boxes, txts, scores, font_path='simfang.ttf')\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result_' + img_name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/08/12 16:01:14] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/simon/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/simon/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/simon/opt/anaconda3/envs/s2s_learning_seminar/lib/python3.11/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/simon/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2', res='html')\n",
      "[[218.0, 131.0], [285.0, 132.0], [285.0, 143.0], [218.0, 142.0]]\n",
      "[[406.0, 130.0], [430.0, 130.0], [430.0, 144.0], [406.0, 144.0]]\n",
      "[[12.0, 122.0], [158.0, 122.0], [158.0, 131.0], [12.0, 131.0]]\n",
      "[[200.0, 120.0], [302.0, 121.0], [302.0, 134.0], [199.0, 133.0]]\n",
      "[[407.0, 120.0], [429.0, 120.0], [429.0, 134.0], [407.0, 134.0]]\n",
      "[[225.0, 112.0], [278.0, 112.0], [278.0, 123.0], [225.0, 123.0]]\n",
      "[[10.0, 111.0], [160.0, 111.0], [160.0, 124.0], [10.0, 124.0]]\n",
      "[[407.0, 110.0], [429.0, 110.0], [429.0, 125.0], [407.0, 125.0]]\n",
      "[[382.0, 102.0], [454.0, 102.0], [454.0, 112.0], [382.0, 112.0]]\n",
      "[[217.0, 102.0], [286.0, 102.0], [286.0, 112.0], [217.0, 112.0]]\n",
      "[[57.0, 100.0], [114.0, 100.0], [114.0, 113.0], [57.0, 113.0]]\n",
      "[[40.0, 78.0], [131.0, 78.0], [131.0, 91.0], [40.0, 91.0]]\n",
      "[[5.0, 70.0], [164.0, 70.0], [164.0, 79.0], [5.0, 79.0]]\n",
      "[[407.0, 69.0], [429.0, 69.0], [429.0, 80.0], [407.0, 80.0]]\n",
      "[[219.0, 69.0], [285.0, 69.0], [285.0, 79.0], [219.0, 79.0]]\n",
      "[[200.0, 59.0], [303.0, 59.0], [303.0, 71.0], [200.0, 71.0]]\n",
      "[[6.0, 59.0], [164.0, 59.0], [164.0, 71.0], [6.0, 71.0]]\n",
      "[[407.0, 57.0], [429.0, 57.0], [429.0, 71.0], [407.0, 71.0]]\n",
      "[[226.0, 49.0], [277.0, 49.0], [277.0, 59.0], [226.0, 59.0]]\n",
      "[[408.0, 48.0], [428.0, 48.0], [428.0, 59.0], [408.0, 59.0]]\n",
      "[[3.0, 46.0], [166.0, 47.0], [166.0, 60.0], [3.0, 59.0]]\n",
      "[[381.0, 25.0], [453.0, 25.0], [453.0, 36.0], [381.0, 36.0]]\n",
      "[[218.0, 25.0], [285.0, 25.0], [285.0, 36.0], [218.0, 36.0]]\n",
      "[[59.0, 25.0], [112.0, 25.0], [112.0, 36.0], [59.0, 36.0]]\n",
      "[[33.0, 4.0], [137.0, 4.0], [137.0, 16.0], [33.0, 16.0]]\n"
     ]
    }
   ],
   "source": [
    "# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n",
    "# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n",
    "# to switch the language model in order.\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=False, res=\"html\") # need to run only once to download and load model into memory\n",
    "img_name = \"PMC515297_004_00.png\"\n",
    "img_path = absolute_dir + '/test/' + img_name\n",
    "result = ocr.ocr(img_path, rec=False)\n",
    "for idx in range(len(result)):\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)\n",
    "\n",
    "# draw result\n",
    "result = result[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "im_show = draw_ocr(image, result, txts=None, scores=None, font_path='/path/to/PaddleOCR/doc/fonts/simfang.ttf')\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('structure_result_' + img_name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaddleocr\u001b[39;00m \u001b[39mimport\u001b[39;00m PPStructure,draw_structure_result,save_structure_res\n\u001b[0;32m----> 2\u001b[0m save_structure_res(result, \u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(img_path)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/s2s_learning_seminar/lib/python3.11/site-packages/paddleocr/ppstructure/predict_system.py:198\u001b[0m, in \u001b[0;36msave_structure_res\u001b[0;34m(res, save_folder, img_name, img_idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    194\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(excel_save_folder, \u001b[39m'\u001b[39m\u001b[39mres_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(img_idx)),\n\u001b[1;32m    195\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    196\u001b[0m         encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    197\u001b[0m     \u001b[39mfor\u001b[39;00m region \u001b[39min\u001b[39;00m res_cp:\n\u001b[0;32m--> 198\u001b[0m         roi_img \u001b[39m=\u001b[39m region\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(json\u001b[39m.\u001b[39mdumps(region)))\n\u001b[1;32m    201\u001b[0m         \u001b[39mif\u001b[39;00m region[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(region[\n\u001b[1;32m    202\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mres\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mhtml\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m region[\u001b[39m'\u001b[39m\u001b[39mres\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from paddleocr import PPStructure, draw_structure_result, save_structure_res\n",
    "\n",
    "save_structure_res(result, \"./\", os.path.basename(img_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PPStructure,save_structure_res\n",
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,draw_structure_result,save_structure_res\n",
    "\n",
    "table_engine = PPStructure(show_log=True, image_orientation=True)\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = 'ppstructure/docs/table/1.png'\n",
    "img = cv2.imread(img_path)\n",
    "result = table_engine(img)\n",
    "save_structure_res(result, save_folder,os.path.basename(img_path).split('.')[0])\n",
    "\n",
    "for line in result:\n",
    "    line.pop('img')\n",
    "    print(line)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "font_path = 'doc/fonts/simfang.ttf' # PaddleOCR下提供字体包\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "im_show = draw_structure_result(image, result,font_path=font_path)\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropped Image OCR\n",
    "https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppstructure/table/README.md#43-calculate-teds\n",
    "\n",
    "Find a script for paddleocr to html inside `convert_labelo2html.py`. It is from the library itself, but I dont know how to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_coordinates = [\n",
    "#     [[218.0, 131.0], [285.0, 132.0], [285.0, 143.0], [218.0, 142.0]],\n",
    "#     [[406.0, 130.0], [430.0, 130.0], [430.0, 144.0], [406.0, 144.0]],\n",
    "#     [[12.0, 122.0], [158.0, 122.0], [158.0, 131.0], [12.0, 131.0]],\n",
    "#     [[200.0, 120.0], [302.0, 121.0], [302.0, 134.0], [199.0, 133.0]],\n",
    "#     [[407.0, 120.0], [429.0, 120.0], [429.0, 134.0], [407.0, 134.0]],\n",
    "#     [[225.0, 112.0], [278.0, 112.0], [278.0, 123.0], [225.0, 123.0]],\n",
    "#     [[10.0, 111.0], [160.0, 111.0], [160.0, 124.0], [10.0, 124.0]],\n",
    "#     [[407.0, 110.0], [429.0, 110.0], [429.0, 125.0], [407.0, 125.0]],\n",
    "#     [[382.0, 102.0], [454.0, 102.0], [454.0, 112.0], [382.0, 112.0]],\n",
    "#     [[217.0, 102.0], [286.0, 102.0], [286.0, 112.0], [217.0, 112.0]],\n",
    "#     [[57.0, 100.0], [114.0, 100.0], [114.0, 113.0], [57.0, 113.0]],\n",
    "#     [[40.0, 78.0], [131.0, 78.0], [131.0, 91.0], [40.0, 91.0]],\n",
    "#     [[5.0, 70.0], [164.0, 70.0], [164.0, 79.0], [5.0, 79.0]],\n",
    "#     [[407.0, 69.0], [429.0, 69.0], [429.0, 80.0], [407.0, 80.0]],\n",
    "#     [[219.0, 69.0], [285.0, 69.0], [285.0, 79.0], [219.0, 79.0]],\n",
    "#     [[200.0, 59.0], [303.0, 59.0], [303.0, 71.0], [200.0, 71.0]],\n",
    "#     [[6.0, 59.0], [164.0, 59.0], [164.0, 71.0], [6.0, 71.0]],\n",
    "#     [[407.0, 57.0], [429.0, 57.0], [429.0, 71.0], [407.0, 71.0]],\n",
    "#     [[226.0, 49.0], [277.0, 49.0], [277.0, 59.0], [226.0, 59.0]],\n",
    "#     [[408.0, 48.0], [428.0, 48.0], [428.0, 59.0], [408.0, 59.0]],\n",
    "#     [[3.0, 46.0], [166.0, 47.0], [166.0, 60.0], [3.0, 59.0]],\n",
    "#     [[381.0, 25.0], [453.0, 25.0], [453.0, 36.0], [381.0, 36.0]],\n",
    "#     [[218.0, 25.0], [285.0, 25.0], [285.0, 36.0], [218.0, 36.0]],\n",
    "#     [[59.0, 25.0], [112.0, 25.0], [112.0, 36.0], [59.0, 36.0]],\n",
    "#     [[33.0, 4.0], [137.0, 4.0], [137.0, 16.0], [33.0, 16.0]]\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def crop_images(coordinates_list, file_path):\n",
    "    # Load the input image (adjust the path accordingly)\n",
    "    input_image = Image.open(file_path)\n",
    "\n",
    "    # Initialize an array to store cropped images\n",
    "    cropped_img_paths = []\n",
    "\n",
    "    for coords in coordinates_list:\n",
    "        # Convert coordinates to integers\n",
    "        coords_int = [(int(x), int(y)) for x, y in coords]\n",
    "        \n",
    "        # Find the minimum and maximum x and y coordinates\n",
    "        x_values, y_values = zip(*coords_int)\n",
    "        min_x = min(x_values)\n",
    "        min_y = min(y_values)\n",
    "        max_x = max(x_values)\n",
    "        max_y = max(y_values)\n",
    "        # Create a cropped image from the input image using the coordinates\n",
    "        cropped_image = input_image.crop((min_x, min_y, max_x, max_y))\n",
    "        \n",
    "        # Append the cropped image to the array\n",
    "        \n",
    "        # Write cropped imgs to table_rectangles_temp dir for further processing\n",
    "        img_path = f'table_rectangles_temp/{file_path.split(\"/\")[-1].split(\".\")[0]}_{min_x}_{min_y}_{max_x}_{max_y}.png'\n",
    "        cropped_image.save(img_path)\n",
    "        cropped_img_paths.append(img_path)\n",
    "    #  Show one image as example:\n",
    "    print(cropped_img_paths[0])\n",
    "    return cropped_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_rectangles_temp/PMC515297_004_00_218_131_285_143.png\n"
     ]
    }
   ],
   "source": [
    "img_name = \"PMC515297_004_00\"\n",
    "img_path = f\"{absolute_dir}/test/{img_name}.png\"\n",
    "cropped_img_paths = crop_images(result, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-12 15:39:15,634] [ WARNING] easyocr.py:71 - Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Feed it into the ocr model\n",
    "import easyocr\n",
    "from tqdm import tqdm\n",
    "reader = easyocr.Reader(['en' ], gpu=False)\n",
    "\n",
    "def perform_ocr(model_ocr_method, cropped_img_paths):\n",
    "    text_results = []\n",
    "    reader = easyocr.Reader(['en' ], gpu=False)\n",
    "        # For loop with progress indicator\n",
    "    for path in tqdm(cropped_img_paths):\n",
    "        result = model_ocr_method(f\"{project_root_dir}/model_exploration/paddleocr/{path}\")\n",
    "        if len(result) == 0:\n",
    "            text = \"\"\n",
    "        else:\n",
    "            text = result[0][1]\n",
    "        text_results.append(text)\n",
    "    return text_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-12 15:39:21,785] [ WARNING] easyocr.py:71 - Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_rectangles_temp/PMC515297_004_00_218_131_285_143.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "print(cropped_img_paths[0])\n",
    "extracted_texsts = perform_ocr(reader.readtext, cropped_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text found in image: chin Populijons\n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: pobuhuerd\n",
      "Text found in image: \n",
      "Text found in image: neraups\n",
      "Text found in image: 6ro\n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: Sroun\n",
      "Text found in image: Lingulstic grouping\n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: RAMadiie\n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: \n",
      "Text found in image: Yo D\n",
      "Text found in image: PercenDE: Yanabon\n",
      "Text found in image: cource o\"inccn\n",
      "Text found in image: S(dups In #\n",
      "Text found in image: ocopriphica\n"
     ]
    }
   ],
   "source": [
    "for text in extracted_texsts: \n",
    "    print(f\"Text found in image: {text}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEDS Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_table(ocr_text, coordinates, threshold=10):\n",
    "    num_cells = len(coordinates)\n",
    "    \n",
    "    html = \"<table border='1'>\\n\"\n",
    "    \n",
    "    current_row = 0\n",
    "    for cell in range(num_celals):\n",
    "        \n",
    "        coords = coordinates[cell]\n",
    "        cell_text = ocr_text[cell]\n",
    "        # print(coords[3][1] < coordinates[cell - 1][3][1] + threshold)\n",
    "        # print(coords[3][1], coordinates[cell - 1][3][1] + threshold)\n",
    "        is_new_row = cell == 0 or coords[3][1] < coordinates[cell - 1][3][1] + threshold\n",
    "        if is_new_row:\n",
    "            html += \"  <tr>\\n\"\n",
    "            current_row += 1\n",
    "        \n",
    "        html += f\"    <td style='border: 1px solid black; padding: 5px;'\"\n",
    "        # html += f\" rowspan='{coords[2] - coords[0]}'\"\n",
    "        # html += f\" colspan='{coords[3] - coords[1]}'\"\n",
    "        html += f\">\\n\"\n",
    "        html += f\"      {cell_text}\\n\"\n",
    "        html += \"    </td>\\n\"\n",
    "        if is_new_row:\n",
    "            html += \"  </tr>\\n\"\n",
    "    \n",
    "    html += \"</table>\"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = generate_html_table(extracted_texsts, test_coordinates)\n",
    "# write html string to txt file\n",
    "with open(\"test_text.txt\", 'w') as file:\n",
    "    file.write(html_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMC5755158_010_01 = '<html><body><table><thead><tr><td></td><td><b>Weaning</b></td><td><b>Week 15</b></td><td><b>Off-test</b></td></tr></thead><tbody><tr><td>Weaning</td><td>–</td><td>–</td><td>–</td></tr><tr><td>Week 15</td><td>–</td><td>0.17 ± 0.08</td><td>0.16 ± 0.03</td></tr><tr><td>Off-test</td><td>–</td><td>0.80 ± 0.24</td><td>0.19 ± 0.09</td></tr></tbody></table></body></html>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teds_score.ted_method import EvaluatorTEDSCUstom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./eval_table.py \\\n",
    "    --det_model_dir=path/to/det_model_dir \\\n",
    "    --rec_model_dir=path/to/rec_model_dir \\\n",
    "    --table_model_dir=path/to/table_model_dir \\\n",
    "    --image_dir=docs/table/table.jpg \\\n",
    "    --rec_char_dict_path=../ppocr/utils/dict/table_dict.txt \\\n",
    "    --table_char_dict_path=../ppocr/utils/dict/table_structure_dict.txt \\ \n",
    "    --det_limit_side_len=736 \\\n",
    "    --det_limit_type=min \\\n",
    "    --gt_path=path/to/gt.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s_learning_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6a6a2f4e9b3d29343f27ef6aef311b54e340d4b6fc29835f858df5c984e5196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
